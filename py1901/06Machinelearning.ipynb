{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]]\n[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#파이썬으로 배우는 머신러닝\n",
    "\n",
    "#머신러닝 변천사\n",
    "#고전적 인공지능 - 신경망 - 머신러닝 - 빅데이터 - 딥러닝\n",
    "\n",
    "#파이썬에서 머신러닝을 테스트 및 구현하려면\n",
    "#numpy, scipy, pandas, matplotlib, scikit-learn 등의 필요\n",
    "#부수적으로 mglearn 패키지도 설치할 것\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import mglearn\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "#boston\n",
    "#wine\n",
    "#cancer\n",
    "#diabetes\n",
    "digits = datasets.load_digits() # 숫자 필기 이미지\n",
    "# lands = datasets.fetch_20newsgroups() #뉴스 그룹 문자자료\n",
    "# faces = datasets.fetch_lfw_people() #얼굴이미지\n",
    "\n",
    "#훈련데이터와 테스트데이터 생성하기 지도학습으로 머신러닝 시스템 구축시\n",
    "#레이블된 데이터가 필요 이러한 데이터를 2개 그룹으로 나눠 작업하는데\n",
    "#특정 작업을 위한 모델 생성 - 훈련데이터\n",
    "#생성된 모델의 작동여부 파악 - 검증데이터\n",
    "\n",
    "#scikit-learn에서는 이러한 작업을 위해 train_test_split 함수제공\n",
    "#데이터는 x로 레이블은 y로 표기함\n",
    "print(iris.data[:5,:])\n",
    "print(iris.target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn 예제 데이터 [[ 9.96346605  4.59676542]\n [11.0329545  -0.16816717]\n [11.54155807  5.21116083]\n [ 8.69289001  1.54322016]\n [ 8.1062269   4.28695977]\n [ 8.30988863  4.80623966]\n [11.93027136  4.64866327]\n [ 9.67284681 -0.20283165]\n [ 8.34810316  5.13415623]\n [ 8.67494727  4.47573059]\n [ 9.17748385  5.09283177]\n [10.24028948  2.45544401]\n [ 8.68937095  1.48709629]\n [ 8.92229526 -0.63993225]\n [ 9.49123469  4.33224792]\n [ 9.25694192  5.13284858]\n [ 7.99815287  4.8525051 ]\n [ 8.18378052  1.29564214]\n [ 8.7337095   2.49162431]\n [ 9.32298256  5.09840649]\n [10.06393839  0.99078055]\n [ 9.50048972 -0.26430318]\n [ 8.34468785  1.63824349]\n [ 9.50169345  1.93824624]\n [ 9.15072323  5.49832246]\n [11.563957    1.3389402 ]] [1 0 1 0 0 1 1 0 1 1 1 1 0 0 1 1 1 0 0 1 0 0 0 0 1 0]\nX데이터 크기 (150, 4)\n훈련 x데이터 (105, 4)\n훈련 y데이터 (105,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TJ\\venv\\py36\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function make_blobs is deprecated; Please import make_blobs directly from scikit-learn\n  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'KNeighborsClassifier' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cf2b468c9139>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'훈련 y데이터'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mknnclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#k분류기 k값 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0mknnclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#모델 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KNeighborsClassifier' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#train_test_split으로 train, test으로 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, train_size=0.7, test_size=0.3, random_state=0)\n",
    "#훈련데이터 레이블 X_train, y_train\n",
    "#테스트데이터 레이블 X_test, y_test\n",
    "\n",
    "# print('훈련데이터 개수', X_train.shape)\n",
    "# print('훈련데이터 개수', y_train.shape)\n",
    "# print('검증데이터 개수', X_test.shape)\n",
    "# print('검증데이터 개수', y_test.shape)\n",
    "#\n",
    "# irisdf = pd.DataFrame(X_train, columns=iris.feature_names)\n",
    "# pd.plotting.scatter_matrix(irisdf, c=y_train, s=50, cmap=mglearn.cm3, alpha=0.8, figsize=(10,10))\n",
    "# plt.show()\n",
    "\n",
    "#KNN분류 알고리즘\n",
    "#KNN 예제용 데이터셋 생성\n",
    "X, y = mglearn.datasets.make_forge()\n",
    "print('knn 예제 데이터', X, y)\n",
    "\n",
    "# mglearn.discrete_scatter(X[:,0], X[:,1],y)\n",
    "# plt.show()\n",
    "# \n",
    "# #새로운 데이터 3개를 추가해서 KNN분류분석 추가된 데이터와 가장 가까운 훈련데이터 k개를 찾음.\n",
    "# #단, k가 3이상인 경우 레이블을 정하기 위한 다수결 채택\n",
    "# #즉, 더 많은 이웃을 가진 데이터가 레이블로 정해짐.\n",
    "# mglearn.plots.plot_knn_classification(n_neighbors=1)\n",
    "# plt.show()\n",
    "# \n",
    "# mglearn.plots.plot_knn_classification(n_neighbors=3)\n",
    "# plt.show()\n",
    "\n",
    "#kNN 예제용 데이터셋을 이용해서 KNN알고리즘 적용\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=0) #데이터를 자동으로 7:3으로 나눔\n",
    "# print('X데이터 크기', X.shape)\n",
    "# print('훈련 x데이터', X_train.shape)\n",
    "# print('훈련 y데이터', y_train.shape)\n",
    "# \n",
    "# from sklearn.neighbors import KNeighborsClassifier #KNN분류기 선언\n",
    "# knnclf = KNeighborsClassifier(n_jobs=3) #k분류기 k값 설정\n",
    "# \n",
    "# knnclf.fit(X_train, y_train) #모델 학습\n",
    "# print('모델 검증', knnclf.predict(X_test), y_test)\n",
    "# print('모델 검증 정확도', knnclf.score(X_test, y_test))\n",
    "#iris 데이터로 KNN\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=0)\n",
    "print('X데이터 크기', X.shape)\n",
    "print('훈련 x데이터', X_train.shape)\n",
    "print('훈련 y데이터', y_train.shape)\n",
    "\n",
    "knnclf = KNeighborsClassifier(n_jobs=2) #k분류기 k값 설정\n",
    "knnclf.fit(X_train, y_train) #모델 학습\n",
    "\n",
    "print('모델 검증', knnclf.predict(X_test), y_test)\n",
    "print('모델 검증 정확도', knnclf.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'knnclf' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a32b8cb6c685>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# new_iris = np.array([[1,1,1,1]]) #예측한 품종 :  ['setosa']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnew_iris\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#예측한 품종 :  ['virginica']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknnclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_iris\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'새로운 데이터로 예측'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'예측한 품종 : '\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0miris\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'knnclf' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#새로운 데이터 예측 - 데이터셋에 존재하지 않는 데이터\n",
    "# new_iris = np.array([[1,1,1,1]]) #예측한 품종 :  ['setosa']\n",
    "new_iris = np.array([[20,20,20,20]]) #예측한 품종 :  ['virginica']\n",
    "result = knnclf.predict(new_iris)\n",
    "print('새로운 데이터로 예측', result)\n",
    "print('예측한 품종 : ',  iris['target_names'][result])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'knnclf' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b535d955b7a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#모델정확도 측정 - confusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcfm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknnclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#오차행렬을 그래프로 표시\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'knnclf' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#모델정확도 측정 - confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cfm = confusion_matrix(y_test, knnclf.predict(X_test))\n",
    "print(cfm)\n",
    "#오차행렬을 그래프로 표시\n",
    "import seaborn as sns\n",
    "\n",
    "# sns.heatmap(cfm, square=True, annot=True, cbar=False, fmt='g', cmap='YlGnBu')\n",
    "# plt.xlabel('predict')\n",
    "# plt.ylabel('versicolor/verginica/setosa')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타이타닉 데이터1\n    PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  \n타이타닉 데이터2\n      PassengerId  Survived  Pclass                                      Name  \\\n886          887         0       2                     Montvila, Rev. Juozas   \n887          888         1       1              Graham, Miss. Margaret Edith   \n888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n889          890         1       1                     Behr, Mr. Karl Howell   \n890          891         0       3                       Dooley, Mr. Patrick   \n\n        Sex   Age  SibSp  Parch      Ticket   Fare Cabin Embarked  \n886    male  27.0      0      0      211536  13.00   NaN        S  \n887  female  19.0      0      0      112053  30.00   B42        S  \n888  female   NaN      1      2  W./C. 6607  23.45   NaN        S  \n889    male  26.0      0      0      111369  30.00  C148        C  \n890    male  32.0      0      0      370376   7.75   NaN        Q  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ddcc8fe66820>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'타이타닉 데이터2\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitanic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtitanic_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitanic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtitanic_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitanic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\TJ\\venv\\py36\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\TJ\\venv\\py36\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\TJ\\venv\\py36\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2485\u001b[0m         \u001b[0;34m\"\"\"Return the cached item, item represents a label indexer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2486\u001b[0m         \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2487\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2489\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#타이타닉 데이터셋을 이용하 KNN분석 1\n",
    "#승객명, 좌석등급, 나이, 성별, 생존여부\n",
    "#iris 데이터로 KNN\n",
    "\n",
    "import pandas as pd\n",
    "# titanic = sns.load_dataset\n",
    "titanic = pd.read_csv('C:/Users/TJ/Google 드라이브/학습자료/프로그래밍/data science/Sample data/r/titanic.csv',  engine='python')\n",
    "print('타이타닉 데이터1\\n', titanic.head())\n",
    "print('타이타닉 데이터2\\n', titanic.tail())\n",
    "\n",
    "titanic_data = titanic[:, 1:4]\n",
    "titanic_target = titanic[:, 4]\n",
    "\n",
    "print('추출된 데이터', titanic_data)\n",
    "print('추출된 데이터', titanic_target)\n",
    "\n",
    "#결측치 처리\n",
    "print(titanic_data.isnull().sum())\n",
    "# 1. 제거, 2. 0으로 대체, 3. 평균, 최대, 최소로 대체\n",
    "# 제거\n",
    "titanic_data = titanic_data.dropna() #1\n",
    "titanic_data = titanic_data['Age'].dropna() #2\n",
    "\n",
    "#카테고리 특성을 수치형으로 변환\n",
    "#좌석등급 1st, 2nd, 3rd => 1,2,3\n",
    "#성별 male, female => 0,1\n",
    "\n",
    "for i in range(len(titanic_data)):\n",
    "    if titanic_data['PClass'][i] == '1st':\n",
    "        titanic_data['PClass'] = 1\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# X = titanic.get\n",
    "# y = titanic.target\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=0)\n",
    "# print('X데이터 크기', X.shape)\n",
    "# print('훈련 x데이터', X_train.shape)\n",
    "# print('훈련 y데이터', y_train.shape)\n",
    "# \n",
    "# knnclf = KNeighborsClassifier(n_jobs=2) #k분류기 k값 설정\n",
    "# knnclf.fit(X_train, y_train) #모델 학습\n",
    "# \n",
    "# print('모델 검증', knnclf.predict(X_test), y_test)\n",
    "# print('모델 검증 정확도', knnclf.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
